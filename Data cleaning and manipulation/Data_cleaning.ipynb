{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a123cf69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading BTC data from: C:\\Users\\User\\Downloads\\KPZHackathon\\final_merged_data_2.csv\n",
      "BTC data loaded successfully. First 5 rows:\n",
      "              datetime  transactions_count_flow_1  current_regime  \\\n",
      "0  2020-04-09 00:00:00                        401               5   \n",
      "1  2020-04-09 01:00:00                        558               5   \n",
      "2  2020-04-09 02:00:00                        633               5   \n",
      "3  2020-04-09 03:00:00                        488               5   \n",
      "4  2020-04-09 04:00:00                        709               5   \n",
      "\n",
      "   predicted_next_regime  next_regime_probability     start_time  inflow_mean  \\\n",
      "0                      5                  0.46246  1586390400000     0.800575   \n",
      "1                      5                  0.46246  1586394000000     0.532598   \n",
      "2                      5                  0.46246  1586397600000     0.531611   \n",
      "3                      5                  0.46246  1586401200000     0.688415   \n",
      "4                      5                  0.46246  1586404800000     1.294126   \n",
      "\n",
      "   inflow_mean_ma7  inflow_top10  inflow_total  ...  outflow_total  \\\n",
      "0         1.037722   1201.414725   1361.777521  ...     895.418032   \n",
      "1         0.985374    903.526470   1100.346962  ...    1061.445288   \n",
      "2         0.963363   1232.476684   1521.470517  ...    1294.982377   \n",
      "3         0.986846    970.117498   1120.050585  ...     955.787655   \n",
      "4         0.749810   2604.244845   2826.370613  ...    2602.917771   \n",
      "\n",
      "   netflow_total  transactions_count_flow_2     Open     High      Low  \\\n",
      "0     466.359489                        401  7311.27  7373.03  7311.27   \n",
      "1      38.901673                        558  7316.73  7372.00  7306.15   \n",
      "2     226.488140                        633  7319.98  7385.44  7319.44   \n",
      "3     164.262931                        488  7358.02  7400.00  7341.38   \n",
      "4     223.452842                        709  7370.85  7376.59  7330.06   \n",
      "\n",
      "     Close      Volume  flow_mean   flow_total  \n",
      "0  7325.30  235.856119  11.683679  4685.155179  \n",
      "1  7327.71  141.574761   7.552804  4214.464499  \n",
      "2  7368.71  161.761294   8.277723  5239.798655  \n",
      "3  7367.36  116.642642   8.438286  4117.883564  \n",
      "4  7356.98  112.308853   9.533256  6759.078698  \n",
      "\n",
      "[5 rows x 23 columns]\n",
      "\n",
      "BTC data after setting datetime index (first 5 rows):\n",
      "                     transactions_count_flow_1  current_regime  \\\n",
      "datetime                                                         \n",
      "2020-04-09 00:00:00                        401               5   \n",
      "2020-04-09 01:00:00                        558               5   \n",
      "2020-04-09 02:00:00                        633               5   \n",
      "2020-04-09 03:00:00                        488               5   \n",
      "2020-04-09 04:00:00                        709               5   \n",
      "\n",
      "                     predicted_next_regime  next_regime_probability  \\\n",
      "datetime                                                              \n",
      "2020-04-09 00:00:00                      5                  0.46246   \n",
      "2020-04-09 01:00:00                      5                  0.46246   \n",
      "2020-04-09 02:00:00                      5                  0.46246   \n",
      "2020-04-09 03:00:00                      5                  0.46246   \n",
      "2020-04-09 04:00:00                      5                  0.46246   \n",
      "\n",
      "                        start_time  inflow_mean  inflow_mean_ma7  \\\n",
      "datetime                                                           \n",
      "2020-04-09 00:00:00  1586390400000     0.800575         1.037722   \n",
      "2020-04-09 01:00:00  1586394000000     0.532598         0.985374   \n",
      "2020-04-09 02:00:00  1586397600000     0.531611         0.963363   \n",
      "2020-04-09 03:00:00  1586401200000     0.688415         0.986846   \n",
      "2020-04-09 04:00:00  1586404800000     1.294126         0.749810   \n",
      "\n",
      "                     inflow_top10  inflow_total  outflow_mean  ...  \\\n",
      "datetime                                                       ...   \n",
      "2020-04-09 00:00:00   1201.414725   1361.777521      2.077536  ...   \n",
      "2020-04-09 01:00:00    903.526470   1100.346962      1.772029  ...   \n",
      "2020-04-09 02:00:00   1232.476684   1521.470517      1.932810  ...   \n",
      "2020-04-09 03:00:00    970.117498   1120.050585      1.866773  ...   \n",
      "2020-04-09 04:00:00   2604.244845   2826.370613      3.503254  ...   \n",
      "\n",
      "                     outflow_total  netflow_total  transactions_count_flow_2  \\\n",
      "datetime                                                                       \n",
      "2020-04-09 00:00:00     895.418032     466.359489                        401   \n",
      "2020-04-09 01:00:00    1061.445288      38.901673                        558   \n",
      "2020-04-09 02:00:00    1294.982377     226.488140                        633   \n",
      "2020-04-09 03:00:00     955.787655     164.262931                        488   \n",
      "2020-04-09 04:00:00    2602.917771     223.452842                        709   \n",
      "\n",
      "                        Open     High      Low    Close      Volume  \\\n",
      "datetime                                                              \n",
      "2020-04-09 00:00:00  7311.27  7373.03  7311.27  7325.30  235.856119   \n",
      "2020-04-09 01:00:00  7316.73  7372.00  7306.15  7327.71  141.574761   \n",
      "2020-04-09 02:00:00  7319.98  7385.44  7319.44  7368.71  161.761294   \n",
      "2020-04-09 03:00:00  7358.02  7400.00  7341.38  7367.36  116.642642   \n",
      "2020-04-09 04:00:00  7370.85  7376.59  7330.06  7356.98  112.308853   \n",
      "\n",
      "                     flow_mean   flow_total  \n",
      "datetime                                     \n",
      "2020-04-09 00:00:00  11.683679  4685.155179  \n",
      "2020-04-09 01:00:00   7.552804  4214.464499  \n",
      "2020-04-09 02:00:00   8.277723  5239.798655  \n",
      "2020-04-09 03:00:00   8.438286  4117.883564  \n",
      "2020-04-09 04:00:00   9.533256  6759.078698  \n",
      "\n",
      "[5 rows x 22 columns]\n",
      "BTC data shape: (43225, 22)\n",
      "\n",
      "Loading Gold data from: C:\\Users\\User\\Downloads\\XAU_1h_data.csv\n",
      "Gold data loaded successfully. First 5 rows:\n",
      "               Date   Open   High    Low  Close  Volume\n",
      "0  2004.06.11 07:00  384.0  384.3  383.3  383.8      44\n",
      "1  2004.06.11 08:00  383.8  384.3  383.1  383.1      41\n",
      "2  2004.06.11 09:00  383.1  384.1  382.8  383.1      55\n",
      "3  2004.06.11 10:00  383.0  383.8  383.0  383.6      33\n",
      "4  2004.06.11 11:00  383.6  383.8  383.5  383.6      23\n",
      "\n",
      "Gold data info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 119794 entries, 0 to 119793\n",
      "Data columns (total 6 columns):\n",
      " #   Column  Non-Null Count   Dtype  \n",
      "---  ------  --------------   -----  \n",
      " 0   Date    119794 non-null  object \n",
      " 1   Open    119794 non-null  float64\n",
      " 2   High    119794 non-null  float64\n",
      " 3   Low     119794 non-null  float64\n",
      " 4   Close   119794 non-null  float64\n",
      " 5   Volume  119794 non-null  int64  \n",
      "dtypes: float64(4), int64(1), object(1)\n",
      "memory usage: 5.5+ MB\n",
      "\n",
      "Gold data after parsing date and setting index (first 5 rows):\n",
      "                      Open   High    Low  Close  Volume\n",
      "time_gold                                              \n",
      "2004-06-11 07:00:00  384.0  384.3  383.3  383.8      44\n",
      "2004-06-11 08:00:00  383.8  384.3  383.1  383.1      41\n",
      "2004-06-11 09:00:00  383.1  384.1  382.8  383.1      55\n",
      "2004-06-11 10:00:00  383.0  383.8  383.0  383.6      33\n",
      "2004-06-11 11:00:00  383.6  383.8  383.5  383.6      23\n",
      "Gold data shape: (119794, 5)\n",
      "\n",
      "Gold data after renaming columns (first 5 rows):\n",
      "                     gold_Open  gold_High  gold_Low  gold_Close  gold_Volume\n",
      "time_gold                                                                   \n",
      "2004-06-11 07:00:00      384.0      384.3     383.3       383.8           44\n",
      "2004-06-11 08:00:00      383.8      384.3     383.1       383.1           41\n",
      "2004-06-11 09:00:00      383.1      384.1     382.8       383.1           55\n",
      "2004-06-11 10:00:00      383.0      383.8     383.0       383.6           33\n",
      "2004-06-11 11:00:00      383.6      383.8     383.5       383.6           23\n",
      "\n",
      "Ensuring Gold data has hourly frequency (resampling if needed)...\n",
      "Gold data after ensuring hourly frequency (first 5 rows):\n",
      "                     gold_Open  gold_High  gold_Low  gold_Close  gold_Volume\n",
      "time_gold                                                                   \n",
      "2004-06-11 07:00:00      384.0      384.3     383.3       383.8           44\n",
      "2004-06-11 08:00:00      383.8      384.3     383.1       383.1           41\n",
      "2004-06-11 09:00:00      383.1      384.1     382.8       383.1           55\n",
      "2004-06-11 10:00:00      383.0      383.8     383.0       383.6           33\n",
      "2004-06-11 11:00:00      383.6      383.8     383.5       383.6           23\n",
      "Gold data (resampled) shape: (180953, 5)\n",
      "\n",
      "Merging the two DataFrames (BTC and Gold)...\n",
      "Data merged successfully. First 5 rows of merged data:\n",
      "                     transactions_count_flow_1  current_regime  \\\n",
      "datetime                                                         \n",
      "2020-04-09 00:00:00                        401               5   \n",
      "2020-04-09 01:00:00                        558               5   \n",
      "2020-04-09 02:00:00                        633               5   \n",
      "2020-04-09 03:00:00                        488               5   \n",
      "2020-04-09 04:00:00                        709               5   \n",
      "\n",
      "                     predicted_next_regime  next_regime_probability  \\\n",
      "datetime                                                              \n",
      "2020-04-09 00:00:00                      5                  0.46246   \n",
      "2020-04-09 01:00:00                      5                  0.46246   \n",
      "2020-04-09 02:00:00                      5                  0.46246   \n",
      "2020-04-09 03:00:00                      5                  0.46246   \n",
      "2020-04-09 04:00:00                      5                  0.46246   \n",
      "\n",
      "                        start_time  inflow_mean  inflow_mean_ma7  \\\n",
      "datetime                                                           \n",
      "2020-04-09 00:00:00  1586390400000     0.800575         1.037722   \n",
      "2020-04-09 01:00:00  1586394000000     0.532598         0.985374   \n",
      "2020-04-09 02:00:00  1586397600000     0.531611         0.963363   \n",
      "2020-04-09 03:00:00  1586401200000     0.688415         0.986846   \n",
      "2020-04-09 04:00:00  1586404800000     1.294126         0.749810   \n",
      "\n",
      "                     inflow_top10  inflow_total  outflow_mean  ...      Low  \\\n",
      "datetime                                                       ...            \n",
      "2020-04-09 00:00:00   1201.414725   1361.777521      2.077536  ...  7311.27   \n",
      "2020-04-09 01:00:00    903.526470   1100.346962      1.772029  ...  7306.15   \n",
      "2020-04-09 02:00:00   1232.476684   1521.470517      1.932810  ...  7319.44   \n",
      "2020-04-09 03:00:00    970.117498   1120.050585      1.866773  ...  7341.38   \n",
      "2020-04-09 04:00:00   2604.244845   2826.370613      3.503254  ...  7330.06   \n",
      "\n",
      "                       Close      Volume  flow_mean   flow_total  gold_Open  \\\n",
      "datetime                                                                      \n",
      "2020-04-09 00:00:00  7325.30  235.856119  11.683679  4685.155179    1645.52   \n",
      "2020-04-09 01:00:00  7327.71  141.574761   7.552804  4214.464499    1645.41   \n",
      "2020-04-09 02:00:00  7368.71  161.761294   8.277723  5239.798655    1647.22   \n",
      "2020-04-09 03:00:00  7367.36  116.642642   8.438286  4117.883564    1646.91   \n",
      "2020-04-09 04:00:00  7356.98  112.308853   9.533256  6759.078698    1647.66   \n",
      "\n",
      "                     gold_High  gold_Low  gold_Close  gold_Volume  \n",
      "datetime                                                           \n",
      "2020-04-09 00:00:00    1647.11   1643.87     1645.40       1213.0  \n",
      "2020-04-09 01:00:00    1647.97   1643.86     1647.10        243.0  \n",
      "2020-04-09 02:00:00    1647.56   1645.09     1647.09       1206.0  \n",
      "2020-04-09 03:00:00    1648.48   1646.13     1647.66        866.0  \n",
      "2020-04-09 04:00:00    1649.27   1646.19     1647.65       1279.0  \n",
      "\n",
      "[5 rows x 27 columns]\n",
      "Merged_df shape before date filtering: (43225, 27)\n",
      "\n",
      "Missing values before specific handling in merged_df:\n",
      "transactions_count_flow_1       0\n",
      "current_regime                  0\n",
      "predicted_next_regime           0\n",
      "next_regime_probability         0\n",
      "start_time                      0\n",
      "inflow_mean                     0\n",
      "inflow_mean_ma7                 0\n",
      "inflow_top10                    0\n",
      "inflow_total                    0\n",
      "outflow_mean                    0\n",
      "outflow_mean_ma7                0\n",
      "outflow_top10                   0\n",
      "outflow_total                   0\n",
      "netflow_total                   0\n",
      "transactions_count_flow_2       0\n",
      "Open                         2541\n",
      "High                         2541\n",
      "Low                          2541\n",
      "Close                        2541\n",
      "Volume                          0\n",
      "flow_mean                       0\n",
      "flow_total                      0\n",
      "gold_Open                    1009\n",
      "gold_High                    1009\n",
      "gold_Low                     1009\n",
      "gold_Close                   1009\n",
      "gold_Volume                  1009\n",
      "dtype: int64\n",
      "\n",
      "Missing values after forward/backward filling Gold columns:\n",
      "gold_Open      0\n",
      "gold_High      0\n",
      "gold_Low       0\n",
      "gold_Close     0\n",
      "gold_Volume    0\n",
      "dtype: int64\n",
      "\n",
      "Filtering merged data from 2020-04-09 to 2025-01-31 (inclusive)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_20304\\1066436707.py:86: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
      "  df2_resampled = df2.resample('H').ffill() # Forward fill any potential gaps\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows before date filter: 43225\n",
      "Number of rows after date filter: 42216\n",
      "\n",
      "Filtered merged data (first 5 rows):\n",
      "                     transactions_count_flow_1  current_regime  \\\n",
      "datetime                                                         \n",
      "2020-04-09 00:00:00                        401               5   \n",
      "2020-04-09 01:00:00                        558               5   \n",
      "2020-04-09 02:00:00                        633               5   \n",
      "2020-04-09 03:00:00                        488               5   \n",
      "2020-04-09 04:00:00                        709               5   \n",
      "\n",
      "                     predicted_next_regime  next_regime_probability  \\\n",
      "datetime                                                              \n",
      "2020-04-09 00:00:00                      5                  0.46246   \n",
      "2020-04-09 01:00:00                      5                  0.46246   \n",
      "2020-04-09 02:00:00                      5                  0.46246   \n",
      "2020-04-09 03:00:00                      5                  0.46246   \n",
      "2020-04-09 04:00:00                      5                  0.46246   \n",
      "\n",
      "                        start_time  inflow_mean  inflow_mean_ma7  \\\n",
      "datetime                                                           \n",
      "2020-04-09 00:00:00  1586390400000     0.800575         1.037722   \n",
      "2020-04-09 01:00:00  1586394000000     0.532598         0.985374   \n",
      "2020-04-09 02:00:00  1586397600000     0.531611         0.963363   \n",
      "2020-04-09 03:00:00  1586401200000     0.688415         0.986846   \n",
      "2020-04-09 04:00:00  1586404800000     1.294126         0.749810   \n",
      "\n",
      "                     inflow_top10  inflow_total  outflow_mean  ...      Low  \\\n",
      "datetime                                                       ...            \n",
      "2020-04-09 00:00:00   1201.414725   1361.777521      2.077536  ...  7311.27   \n",
      "2020-04-09 01:00:00    903.526470   1100.346962      1.772029  ...  7306.15   \n",
      "2020-04-09 02:00:00   1232.476684   1521.470517      1.932810  ...  7319.44   \n",
      "2020-04-09 03:00:00    970.117498   1120.050585      1.866773  ...  7341.38   \n",
      "2020-04-09 04:00:00   2604.244845   2826.370613      3.503254  ...  7330.06   \n",
      "\n",
      "                       Close      Volume  flow_mean   flow_total  gold_Open  \\\n",
      "datetime                                                                      \n",
      "2020-04-09 00:00:00  7325.30  235.856119  11.683679  4685.155179    1645.52   \n",
      "2020-04-09 01:00:00  7327.71  141.574761   7.552804  4214.464499    1645.41   \n",
      "2020-04-09 02:00:00  7368.71  161.761294   8.277723  5239.798655    1647.22   \n",
      "2020-04-09 03:00:00  7367.36  116.642642   8.438286  4117.883564    1646.91   \n",
      "2020-04-09 04:00:00  7356.98  112.308853   9.533256  6759.078698    1647.66   \n",
      "\n",
      "                     gold_High  gold_Low  gold_Close  gold_Volume  \n",
      "datetime                                                           \n",
      "2020-04-09 00:00:00    1647.11   1643.87     1645.40       1213.0  \n",
      "2020-04-09 01:00:00    1647.97   1643.86     1647.10        243.0  \n",
      "2020-04-09 02:00:00    1647.56   1645.09     1647.09       1206.0  \n",
      "2020-04-09 03:00:00    1648.48   1646.13     1647.66        866.0  \n",
      "2020-04-09 04:00:00    1649.27   1646.19     1647.65       1279.0  \n",
      "\n",
      "[5 rows x 27 columns]\n",
      "\n",
      "Filtered merged data (last 5 rows):\n",
      "                     transactions_count_flow_1  current_regime  \\\n",
      "datetime                                                         \n",
      "2025-01-31 19:00:00                        325               4   \n",
      "2025-01-31 20:00:00                        248               0   \n",
      "2025-01-31 21:00:00                        268               4   \n",
      "2025-01-31 22:00:00                        297               4   \n",
      "2025-01-31 23:00:00                        230               4   \n",
      "\n",
      "                     predicted_next_regime  next_regime_probability  \\\n",
      "datetime                                                              \n",
      "2025-01-31 19:00:00                      4                 0.479277   \n",
      "2025-01-31 20:00:00                      0                 0.523820   \n",
      "2025-01-31 21:00:00                      4                 0.479277   \n",
      "2025-01-31 22:00:00                      4                 0.479277   \n",
      "2025-01-31 23:00:00                      4                 0.479277   \n",
      "\n",
      "                        start_time  inflow_mean  inflow_mean_ma7  \\\n",
      "datetime                                                           \n",
      "2025-01-31 19:00:00  1738350000000     0.661799         1.311890   \n",
      "2025-01-31 20:00:00  1738353600000     0.938145         1.217422   \n",
      "2025-01-31 21:00:00  1738357200000     0.861813         1.138473   \n",
      "2025-01-31 22:00:00  1738360800000     0.986986         1.088245   \n",
      "2025-01-31 23:00:00  1738364400000     0.391703         0.990557   \n",
      "\n",
      "                     inflow_top10  inflow_total  outflow_mean  ...       Low  \\\n",
      "datetime                                                       ...             \n",
      "2025-01-31 19:00:00   2118.216026   2176.656820     12.978447  ...  102066.0   \n",
      "2025-01-31 20:00:00   2581.154492   2637.125536      8.558329  ...  101528.0   \n",
      "2025-01-31 21:00:00   2686.885090   2731.084758      7.435033  ...  101303.0   \n",
      "2025-01-31 22:00:00   2498.420345   2521.748144      7.617740  ...  101904.0   \n",
      "2025-01-31 23:00:00    784.904651    805.340602      4.090950  ...  101934.0   \n",
      "\n",
      "                        Close      Volume  flow_mean   flow_total  gold_Open  \\\n",
      "datetime                                                                       \n",
      "2025-01-31 19:00:00  102271.0  291.508387  22.110357  7185.865929    2807.28   \n",
      "2025-01-31 20:00:00  101613.0  258.265339  29.830374  7397.932719    2808.75   \n",
      "2025-01-31 21:00:00  102098.0  106.040989  18.350651  4917.974453    2799.01   \n",
      "2025-01-31 22:00:00  102239.0   29.967345  14.107429  4189.906377    2796.24   \n",
      "2025-01-31 23:00:00  102412.0   22.396461  17.414535  4005.342960    2801.15   \n",
      "\n",
      "                     gold_High  gold_Low  gold_Close  gold_Volume  \n",
      "datetime                                                           \n",
      "2025-01-31 19:00:00    2816.08   2802.93     2808.76       5761.0  \n",
      "2025-01-31 20:00:00    2808.91   2795.31     2798.91       5729.0  \n",
      "2025-01-31 21:00:00    2802.86   2795.54     2796.30       4607.0  \n",
      "2025-01-31 22:00:00    2802.10   2794.34     2800.88       5277.0  \n",
      "2025-01-31 23:00:00    2802.70   2798.50     2799.23       1915.0  \n",
      "\n",
      "[5 rows x 27 columns]\n",
      "\n",
      "Final merged and filtered data info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "DatetimeIndex: 42216 entries, 2020-04-09 00:00:00 to 2025-01-31 23:00:00\n",
      "Data columns (total 27 columns):\n",
      " #   Column                     Non-Null Count  Dtype  \n",
      "---  ------                     --------------  -----  \n",
      " 0   transactions_count_flow_1  42216 non-null  int64  \n",
      " 1   current_regime             42216 non-null  int64  \n",
      " 2   predicted_next_regime      42216 non-null  int64  \n",
      " 3   next_regime_probability    42216 non-null  float64\n",
      " 4   start_time                 42216 non-null  int64  \n",
      " 5   inflow_mean                42216 non-null  float64\n",
      " 6   inflow_mean_ma7            42216 non-null  float64\n",
      " 7   inflow_top10               42216 non-null  float64\n",
      " 8   inflow_total               42216 non-null  float64\n",
      " 9   outflow_mean               42216 non-null  float64\n",
      " 10  outflow_mean_ma7           42216 non-null  float64\n",
      " 11  outflow_top10              42216 non-null  float64\n",
      " 12  outflow_total              42216 non-null  float64\n",
      " 13  netflow_total              42216 non-null  float64\n",
      " 14  transactions_count_flow_2  42216 non-null  int64  \n",
      " 15  Open                       40179 non-null  float64\n",
      " 16  High                       40179 non-null  float64\n",
      " 17  Low                        40179 non-null  float64\n",
      " 18  Close                      40179 non-null  float64\n",
      " 19  Volume                     42216 non-null  float64\n",
      " 20  flow_mean                  42216 non-null  float64\n",
      " 21  flow_total                 42216 non-null  float64\n",
      " 22  gold_Open                  42216 non-null  float64\n",
      " 23  gold_High                  42216 non-null  float64\n",
      " 24  gold_Low                   42216 non-null  float64\n",
      " 25  gold_Close                 42216 non-null  float64\n",
      " 26  gold_Volume                42216 non-null  float64\n",
      "dtypes: float64(22), int64(5)\n",
      "memory usage: 9.0 MB\n",
      "\n",
      "Merged and filtered data saved to: C:\\Users\\User\\Downloads\\KPZHackathon\\merged_btc_gold_hourly_data_filtered.csv\n",
      "\n",
      "--- Data Merging, Filtering, and Saving Process Completed Successfully ---\n",
      "Total rows in the final DataFrame: 42216\n",
      "Columns in the final DataFrame: ['transactions_count_flow_1', 'current_regime', 'predicted_next_regime', 'next_regime_probability', 'start_time', 'inflow_mean', 'inflow_mean_ma7', 'inflow_top10', 'inflow_total', 'outflow_mean', 'outflow_mean_ma7', 'outflow_top10', 'outflow_total', 'netflow_total', 'transactions_count_flow_2', 'Open', 'High', 'Low', 'Close', 'Volume', 'flow_mean', 'flow_total', 'gold_Open', 'gold_High', 'gold_Low', 'gold_Close', 'gold_Volume']\n",
      "Date range in final DataFrame: 2020-04-09 00:00:00 to 2025-01-31 23:00:00\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os # Added os module to help with path creation\n",
    "\n",
    "def load_and_clean_data(btc_file_path, gold_file_path, output_directory, start_date_str, end_date_str):\n",
    "    \"\"\"\n",
    "    Loads, cleans, merges BTC and Gold time series data, filters by date, and saves the result.\n",
    "\n",
    "    Args:\n",
    "        btc_file_path (str): File path for the BTC-USD CSV data.\n",
    "        gold_file_path (str): File path for the new Gold CSV data.\n",
    "        output_directory (str): Directory where the merged CSV will be saved.\n",
    "        start_date_str (str): Start date for filtering (YYYY-MM-DD).\n",
    "        end_date_str (str): End date for filtering (YYYY-MM-DD).\n",
    "\n",
    "\n",
    "    Returns:\n",
    "        pandas.DataFrame: A merged and filtered DataFrame with hourly data, or None if an error occurs.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # --- Load the first dataset (BTC-USD) ---\n",
    "        print(f\"Loading BTC data from: {btc_file_path}\")\n",
    "        df1 = pd.read_csv(btc_file_path)\n",
    "        print(\"BTC data loaded successfully. First 5 rows:\")\n",
    "        print(df1.head())\n",
    "\n",
    "        # Convert 'datetime' column to datetime objects and set as index\n",
    "        df1['datetime'] = pd.to_datetime(df1['datetime'])\n",
    "        df1.set_index('datetime', inplace=True)\n",
    "        df1.sort_index(inplace=True)\n",
    "        print(\"\\nBTC data after setting datetime index (first 5 rows):\")\n",
    "        print(df1.head())\n",
    "        print(f\"BTC data shape: {df1.shape}\")\n",
    "\n",
    "\n",
    "        # --- Load the second dataset (New Gold Data) ---\n",
    "        print(f\"\\nLoading Gold data from: {gold_file_path}\")\n",
    "        # The new gold data uses ';' as a separator and has a specific date format.\n",
    "        df2 = pd.read_csv(gold_file_path, sep=';')\n",
    "        print(\"Gold data loaded successfully. First 5 rows:\")\n",
    "        print(df2.head())\n",
    "        print(\"\\nGold data info:\")\n",
    "        df2.info()\n",
    "\n",
    "\n",
    "        # Rename the date column for consistency, e.g., from 'Date' to 'time'\n",
    "        # Assuming the date column in the new gold CSV is named 'Date'\n",
    "        if 'Date' not in df2.columns:\n",
    "            # Attempt to find a date-like column if 'Date' is not present\n",
    "            # This is a simple check; more robust detection might be needed for varied files\n",
    "            date_col_candidate = None\n",
    "            for col in df2.columns:\n",
    "                if 'date' in col.lower() or 'time' in col.lower():\n",
    "                    date_col_candidate = col\n",
    "                    break\n",
    "            if date_col_candidate:\n",
    "                print(f\"Warning: 'Date' column not found. Using '{date_col_candidate}' as date column.\")\n",
    "                df2.rename(columns={date_col_candidate: 'time_gold'}, inplace=True)\n",
    "            else:\n",
    "                raise ValueError(\"Date column ('Date' or similar) not found in Gold CSV. Please check the CSV header.\")\n",
    "        else:\n",
    "            df2.rename(columns={'Date': 'time_gold'}, inplace=True)\n",
    "\n",
    "\n",
    "        # Convert 'time_gold' column to datetime objects\n",
    "        # The format is 'YYYY.MM.DD HH:MM'\n",
    "        df2['time_gold'] = pd.to_datetime(df2['time_gold'], format='%Y.%m.%d %H:%M')\n",
    "        df2.set_index('time_gold', inplace=True)\n",
    "        df2.sort_index(inplace=True)\n",
    "        print(\"\\nGold data after parsing date and setting index (first 5 rows):\")\n",
    "        print(df2.head())\n",
    "        print(f\"Gold data shape: {df2.shape}\")\n",
    "\n",
    "        # Rename columns in df2 to avoid conflicts (e.g., 'Open' to 'gold_Open')\n",
    "        # The columns in the new gold data are 'Open', 'High', 'Low', 'Close', 'Volume'\n",
    "        df2_columns_renamed = {col: f\"gold_{col}\" for col in df2.columns}\n",
    "        df2 = df2.rename(columns=df2_columns_renamed)\n",
    "        print(\"\\nGold data after renaming columns (first 5 rows):\")\n",
    "        print(df2.head())\n",
    "\n",
    "        # The new gold data is already hourly.\n",
    "        # If there were any irregularities or if we wanted to ensure perfect hourly frequency alignment,\n",
    "        # resampling could be used, but it might not be strictly necessary if data is clean.\n",
    "        # For safety and consistency with previous logic, we can resample.\n",
    "        # This will also ensure the DatetimeIndex has a frequency set.\n",
    "        print(\"\\nEnsuring Gold data has hourly frequency (resampling if needed)...\")\n",
    "        df2_resampled = df2.resample('H').ffill() # Forward fill any potential gaps\n",
    "        print(\"Gold data after ensuring hourly frequency (first 5 rows):\")\n",
    "        print(df2_resampled.head())\n",
    "        print(f\"Gold data (resampled) shape: {df2_resampled.shape}\")\n",
    "\n",
    "\n",
    "        # --- Merge the two DataFrames ---\n",
    "        print(\"\\nMerging the two DataFrames (BTC and Gold)...\")\n",
    "        # Using a 'left' merge to keep all timestamps from df1 (BTC data)\n",
    "        # and match df2_resampled (Gold data).\n",
    "        merged_df = pd.merge(df1, df2_resampled, left_index=True, right_index=True, how='left')\n",
    "        print(\"Data merged successfully. First 5 rows of merged data:\")\n",
    "        print(merged_df.head())\n",
    "        print(f\"Merged_df shape before date filtering: {merged_df.shape}\")\n",
    "\n",
    "\n",
    "        # --- Data Cleaning: Handling Missing Values after Merge ---\n",
    "        print(f\"\\nMissing values before specific handling in merged_df:\\n{merged_df.isnull().sum()}\")\n",
    "        # Forward fill missing values that might have resulted from the left merge for gold columns\n",
    "        gold_cols = [col for col in merged_df.columns if col.startswith('gold_')]\n",
    "        if gold_cols:\n",
    "            merged_df[gold_cols] = merged_df[gold_cols].ffill()\n",
    "            # Optionally, backward fill any remaining NaNs at the beginning\n",
    "            merged_df[gold_cols] = merged_df[gold_cols].bfill()\n",
    "            print(\"\\nMissing values after forward/backward filling Gold columns:\")\n",
    "            print(merged_df[gold_cols].isnull().sum())\n",
    "\n",
    "\n",
    "        # --- Filter by Date Range ---\n",
    "        print(f\"\\nFiltering merged data from {start_date_str} to {end_date_str} (inclusive)...\")\n",
    "        # Convert string dates to datetime objects for filtering\n",
    "        start_datetime = pd.to_datetime(start_date_str + \" 00:00:00\") # Inclusive start of the day\n",
    "        end_datetime = pd.to_datetime(end_date_str + \" 23:59:59\")   # Inclusive end of the day\n",
    "\n",
    "        # Ensure the index is a DatetimeIndex (should be already)\n",
    "        merged_df.index = pd.to_datetime(merged_df.index)\n",
    "\n",
    "        original_rows_before_filter = len(merged_df)\n",
    "        merged_df_filtered = merged_df[(merged_df.index >= start_datetime) & (merged_df.index <= end_datetime)]\n",
    "        print(f\"Number of rows before date filter: {original_rows_before_filter}\")\n",
    "        print(f\"Number of rows after date filter: {len(merged_df_filtered)}\")\n",
    "\n",
    "        if merged_df_filtered.empty:\n",
    "            print(f\"Warning: No data found in the specified date range: {start_date_str} to {end_date_str}.\")\n",
    "            print(\"Please check the date range and the date coverage of your input files.\")\n",
    "        else:\n",
    "            print(\"\\nFiltered merged data (first 5 rows):\")\n",
    "            print(merged_df_filtered.head())\n",
    "            print(\"\\nFiltered merged data (last 5 rows):\")\n",
    "            print(merged_df_filtered.tail())\n",
    "\n",
    "        print(\"\\nFinal merged and filtered data info:\")\n",
    "        merged_df_filtered.info()\n",
    "\n",
    "\n",
    "        # --- Save the merged and filtered DataFrame ---\n",
    "        output_filename = \"merged_btc_gold_hourly_data_filtered.csv\"\n",
    "        output_path = os.path.join(output_directory, output_filename)\n",
    "\n",
    "        if not os.path.exists(output_directory):\n",
    "            os.makedirs(output_directory)\n",
    "            print(f\"\\nCreated output directory: {output_directory}\")\n",
    "\n",
    "        merged_df_filtered.to_csv(output_path)\n",
    "        print(f\"\\nMerged and filtered data saved to: {output_path}\")\n",
    "\n",
    "        return merged_df_filtered\n",
    "\n",
    "    except FileNotFoundError as e:\n",
    "        print(f\"Error: File not found. Please check the file paths. Details: {e}\")\n",
    "        return None\n",
    "    except ValueError as e: # Catch specific errors like date parsing or column not found\n",
    "        print(f\"Error during data processing: {e}\")\n",
    "        return None\n",
    "    except Exception as e:\n",
    "        print(f\"An unexpected error occurred: {e}\")\n",
    "        return None\n",
    "\n",
    "# --- Configuration: File Paths and Date Range ---\n",
    "# Path to the BTC-USD data\n",
    "btc_file_path = r\"C:\\Users\\User\\Downloads\\KPZHackathon\\final_merged_data_2.csv\"\n",
    "\n",
    "# Path to the NEW Gold data\n",
    "new_gold_file_path = r\"C:\\Users\\User\\Downloads\\XAU_1h_data.csv\"\n",
    "\n",
    "# Directory to save the output file\n",
    "output_dir = r\"C:\\Users\\User\\Downloads\\KPZHackathon\"\n",
    "\n",
    "# Desired date range for the final output\n",
    "filter_start_date = \"2020-04-09\"\n",
    "filter_end_date = \"2025-01-31\" # Note: Data will only go up to the latest available in your inputs.\n",
    "\n",
    "# Call the function to load, merge, filter, and save data\n",
    "final_dataframe = load_and_clean_data(btc_file_path, new_gold_file_path, output_dir, filter_start_date, filter_end_date)\n",
    "\n",
    "if final_dataframe is not None and not final_dataframe.empty:\n",
    "    print(\"\\n--- Data Merging, Filtering, and Saving Process Completed Successfully ---\")\n",
    "    print(f\"Total rows in the final DataFrame: {len(final_dataframe)}\")\n",
    "    print(f\"Columns in the final DataFrame: {final_dataframe.columns.tolist()}\")\n",
    "    print(f\"Date range in final DataFrame: {final_dataframe.index.min()} to {final_dataframe.index.max()}\")\n",
    "elif final_dataframe is not None and final_dataframe.empty:\n",
    "    print(\"\\n--- Data Merging and Saving Process Completed, but the DataFrame is EMPTY after filtering. ---\")\n",
    "    print(\"This means no data matched your specified date range or other criteria.\")\n",
    "else:\n",
    "    print(\"\\n--- Data Merging, Filtering, and Saving Process Failed ---\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
